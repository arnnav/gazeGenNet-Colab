{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69HKt8_3yiAg"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "soLkrirRyvFy",
    "outputId": "d3652015-be4a-419d-b1a4-2fdff6dd54df"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "siHcDXDYAzxW",
    "outputId": "ab71a474-5427-486a-a984-802eed4b8dfa"
   },
   "outputs": [],
   "source": [
    "cd '/content/drive/My Drive/Independent Study/Code/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZokJhjaNfzrw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from tensorflow.keras import Model\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G4rSTs5DgKOL"
   },
   "outputs": [],
   "source": [
    "# with open(\"data.unpaired_clean_augment.pkl\", 'rb') as f:\n",
    "#   train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ex8FsG5_X_X"
   },
   "outputs": [],
   "source": [
    "# t,x,y,status,evt=[],[],[],[],[]\n",
    "# for i in train_data:\n",
    "#   for data in i:\n",
    "#     # t.append(data[0])\n",
    "#     x.append(data[1])\n",
    "#     y.append(data[2])\n",
    "#     status.append(data[3])\n",
    "#     evt.append(data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eoc_ygp3BbvG"
   },
   "outputs": [],
   "source": [
    "# df_train = pd.DataFrame(list(zip(x,y,status,evt)),columns =['x', 'y', 'status', 'evt'])\n",
    "# df_train[\"status\"] = df_train[\"status\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cv0OXKjZAeNm"
   },
   "outputs": [],
   "source": [
    "df_X_Train = pd.read_csv(\"LundX.csv\")\n",
    "df_Y_Train = pd.read_csv(\"LundY.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiMl_AF7h-cL"
   },
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)        \n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-JQ3Y9ajtsd"
   },
   "outputs": [],
   "source": [
    "time_steps = 100\n",
    "X_train, y_train = create_dataset(df_X_Train, df_Y_Train, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YwAG-0H994gX"
   },
   "outputs": [],
   "source": [
    "def gaussian2d(x1, x2, mu1, mu2, s1, s2, rho):\n",
    "    # define gaussian mdn (eq 24, 25 from http://arxiv.org/abs/1308.0850)\n",
    "    x_mu1 = tf.subtract(x1, mu1)\n",
    "    x_mu2 = tf.subtract(x2, mu2)\n",
    "    Z = tf.square(tf.compat.v1.div(x_mu1, s1)) + \\\n",
    "        tf.square(tf.compat.v1.div(x_mu2, s2)) - \\\n",
    "        2*tf.compat.v1.div(tf.multiply(rho, tf.multiply(x_mu1, x_mu2)), tf.multiply(s1, s2))\n",
    "    rho_square_term = 1-tf.square(rho)\n",
    "    power_e = tf.exp(tf.compat.v1.div(-Z,2*rho_square_term))\n",
    "    regularize_term = 2*np.pi*tf.multiply(tf.multiply(s1, s2), tf.sqrt(rho_square_term))\n",
    "    gaussian = tf.compat.v1.div(power_e, regularize_term)\n",
    "    return gaussian\n",
    "\n",
    "def get_loss(pi, x1_data, x2_data, eos_data, evt_data, mu1, mu2, sigma1, sigma2, rho, eos, evt):\n",
    "# define loss function (eq 26 of http://arxiv.org/abs/1308.0850)\n",
    "  gaussian = gaussian2d(x1_data, x2_data, mu1, mu2, sigma1, sigma2, rho)\n",
    "  term1 = tf.multiply(gaussian, pi)\n",
    "  term1 = tf.reduce_sum(input_tensor=term1, axis=1, keepdims=True) #do inner summation\n",
    "  term1 = -tf.math.log(tf.maximum(term1, 1e-20)) # some errors are zero -> numerical errors.\n",
    "\n",
    "  term2 = tf.multiply(eos, eos_data) + tf.multiply(1-eos, 1-eos_data) #modified Bernoulli -> eos probability\n",
    "  term2 = -tf.math.log(tf.maximum(term2, 1e-20)) #negative log error gives loss\n",
    "\n",
    "  term3 = tf.nn.sigmoid_cross_entropy_with_logits(evt, evt_data, name=None)\n",
    "\n",
    "  return term1, term2, term3\n",
    "\n",
    "  #transform dense NN outputs into params for MDN\n",
    "def get_mdn_coef(Z):\n",
    "  # returns the tf slices containing mdn dist params (eq 18...23 of http://arxiv.org/abs/1308.0850)\n",
    "  eos_hat = Z[:, 0:1] #end of event tokens\n",
    "  evt_hat = Z[:, 1:3+1] #evt\n",
    "\n",
    "  pi_hat, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, rho_hat = tf.split(Z[:, 3+1:], 6, 1)\n",
    "  pi_hat, sigma1_hat, sigma2_hat = \\\n",
    "                              pi_hat, sigma1_hat, sigma2_hat # these are useful for bias method during sampling\n",
    "\n",
    "  eos = tf.sigmoid(1*eos_hat)\n",
    "  pi = tf.nn.softmax(pi_hat) # softmax z_pi:\n",
    "  mu1 = mu1_hat; mu2 = mu2_hat # leave mu1, mu2 as they are\n",
    "  sigma1 = tf.exp(sigma1_hat); sigma2 = tf.exp(sigma2_hat) # exp for sigmas\n",
    "  rho = tf.tanh(rho_hat) # tanh for rho (squish between -1 and 1)\n",
    "\n",
    "  return [eos, evt_hat, pi, mu1, mu2, sigma1, sigma2, rho]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8iqVCSxOe0n"
   },
   "outputs": [],
   "source": [
    "class mdn(keras.layers.Layer):\n",
    "    def __init__(self,rnn_size=128,n_out=124,**kwargs):\n",
    "        super(mdn, self).__init__()\n",
    "        # n_out = 3 + 1 + 20 * 6\n",
    "        graves_initializer = tf.initializers.TruncatedNormal(mean=0.,stddev=.075,seed=None)\n",
    "        self.mdn_w = tf.Variable(initial_value = graves_initializer(shape=[rnn_size, n_out], dtype=tf.float64),name=\"output_w\",trainable=True)\n",
    "        self.mdn_b = tf.Variable(initial_value = graves_initializer(shape=[n_out], dtype=tf.float64),name=\"output_b\",trainable=True)\n",
    "      \n",
    "\n",
    "    def call(self, outputs):\n",
    "      output = tf.reshape(outputs, [-1, 128])\n",
    "      output = tf.compat.v1.nn.xw_plus_b(output, self.mdn_w, self.mdn_b)\n",
    "      return output\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "      config = super().get_config().copy()\n",
    "      return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0PJrWHhgL-0"
   },
   "outputs": [],
   "source": [
    "def get_final_loss(y_true, y_pred):\n",
    "   \n",
    "    x1_data = tf.gather(y_true,[0],axis=1)\n",
    "    x2_data = tf.gather(y_true,[1],axis=1)\n",
    "    eos_data = tf.gather(y_true,[2],axis=1)\n",
    "    evt_data = tf.gather(y_true,[3,4,5],axis=1)\n",
    "    [eos, evt,pi, mu1, mu2, sigma1,sigma2, rho] = get_mdn_coef(y_pred)\n",
    "\n",
    "    losses = get_loss(pi, x1_data, x2_data, eos_data, evt_data, \\\n",
    "                            mu1, mu2, sigma1, sigma2, rho, \\\n",
    "                            eos, evt)\n",
    "    \n",
    "    loss = tf.reduce_sum(sum(losses))\n",
    "    cost = loss / (50 * 100)\n",
    "    return cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QUuHJS5EojS2"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128,dropout=0.25,return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(128,dropout=0.25,return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(128,dropout=0.25))\n",
    "model.add(mdn())\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(clipnorm=10.0,learning_rate = 0.001,momentum=0.9,decay=0.9),loss=get_final_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sha_pAnq1A9V"
   },
   "outputs": [],
   "source": [
    "epochs = 100000\n",
    "step_ = 2000\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMeDkl8M2BPh"
   },
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.RMSprop(clipnorm=10.0,learning_rate = 0.001,momentum=0.9,decay=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8ELBDuV6Uu-"
   },
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, model=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmWXU3au0whg"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).repeat().batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "WVpoo2FR0p6_",
    "outputId": "941da2e8-e2b1-4194-ab7d-aecdea28ea76"
   },
   "outputs": [],
   "source": [
    "ckpt.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "  print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "else:\n",
    "  print(\"Initializing from scratch.\")\n",
    "\n",
    "epochs_done = manager.checkpoint.save_counter.numpy()\n",
    "for epoch in range(epochs_done,epochs):\n",
    "  avg_loss = []\n",
    "  for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "\n",
    "      with tf.GradientTape() as tape:\n",
    "          logits = model(x_batch_train, training=True)  \n",
    "          loss_value = get_final_loss(y_batch_train, logits)\n",
    "\n",
    "      grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "      optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "      avg_loss.append(loss_value)\n",
    "      if(step == step_):\n",
    "        break\n",
    "  save_path = manager.save(checkpoint_number=epoch)\n",
    "  print(\"Average Training loss --- epoch %d: %.4f\"% (epoch, float(sum(avg_loss)/len(avg_loss))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GOss-w7F3fvx"
   },
   "outputs": [],
   "source": [
    "model.save(\"model_training_steps\")\n",
    "model.save(\"model_training_steps_h5.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gazeGenNet_training_customLayer_tstpes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
